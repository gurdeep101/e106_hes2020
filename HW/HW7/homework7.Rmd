 ---
title: 'CSCI E-106:Assignment 7'
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Due Date: November 9, 2020 at 7:20 pm EST
### Instructions

Students should submit their reports on Canvas. The report needs to clearly state what question is being solved, step-by-step walk-through solutions, and final answers clearly indicated. Please solve by hand where appropriate.

Please submit two files: (1) a R Markdown file (.Rmd extension) and (2) a PDF document, word, or html generated using knitr for the .Rmd file submitted in (1) where appropriate. Please, use RStudio Cloud for your solutions.

----------------------------------------------------


## Problem 1

Use the fortune data under the faraway r library, data(fortune,package="faraway"). The wealth in billions of dollars for 232 billionaires is given in fortune. (50 points, 10 points each) (Hint: refer to the interaction.pdf and rmd files for details)

a-)Plot the wealth as a function of age using a different plotting symbol for the different regions of the world.

```{r}
rm(list = ls())

# change to local path before running
setwd("~/OneDrive/courses/e106/e106_hes2020/HW/HW7") 

library(ggplot2)
library(MASS)
library(onewaytests)
library(lmtest)

data("fortune", package = 'faraway')
head(fortune)
summary(fortune) # shows 5 NA values 
str(fortune)

# remove NA values
fortune <- na.omit(fortune)
summary(fortune) # na values gone

plot(wealth~age, fortune, pch = unclass(region), main = 'Wealth vs Age')

```

All values are in a single plot. Even with separate symbols for region it is difficult to make any interpretations.

b-)Plot the wealth as a function of age with a separate panel for each region.

```{r}
ggplot(aes(x=age, y = wealth), data = fortune) + geom_point() + facet_wrap(~region)
```

Separate plots for each region give a much more clear view.

c-)Determine a transformation on the response to facilitate linear modeling.

```{r}
reg1c <- lm(wealth~., data = fortune)
summary(reg1c)
boxcox(reg1c, lambda = seq(-2, 2, by = 0.1))

```

lambda has MLE value at -1 as seen above. This means that we take reciprocal of y

d-)What is the relationship of age and region to wealth?

Age and wealth appear to have a linear relationship though in all cases the values are concentrated between 40 and 80 years with a few outliers present.

Regions E & U have high concentration of wealthy people while region M has the lowest. Region M also has the largest outlier value.

Across all regions the relationship appears linear with concentration around the 40 to 80 age bracket

e-)Check the assumptions of your model using appropriate diagnostics.

```{r}
# Check for assumptions of simple regression model

# SW Test for normality
# Ho : Errors are normally distributed
# Ha : Errors are not normally distributed
shapiro.test(reg1c$residuals)

# BP Test for constancy of error variance
bptest(reg1c)
# Ho : Errors are normally distributed; no heteroskedasticicty
# Ha : Errors are not normally distributed
# Decision Rule: p-value > 0.05 ==> Accept Ho

# Residual plots
newer.par = par(mfrow = c(2,2))
plot(reg1c)
newer.par

```

The SW test has a p-value < 0.05 and hence we conclude that errors are normally distributed

The BP test provides a p-value of 0.1095 and hence we reject Ho and conclude that heteroskedasticity is present.

From the residuals vs fitted values plot we see that the errors are present in groups - possibly on account of regions and hence not random. Outliers are also present

The QQ plot line is not at 45 degrees and points to non-normal distribution.

As seen the results of statistical tests are contradicting the actual plots. We further attempt transformation as indicated by the BoxCox test.

```{r}
# Fit transformation using reciprocal as per BoxCox test
reg1e <- lm((1/wealth)~., data = fortune)
summary(reg1e)

# Check for assumptions of simple regression model

# SW Test for normality
# Ho : Errors are normally distributed
# Ha : Errors are not normally distributed
shapiro.test(reg1e$residuals)

# BP Test for constancy of error variance
bptest(reg1e)
# Ho : Errors are normally distributed; no heteroskedasticicty
# Ha : Errors are not normally distributed
# Decision Rule: p-value > 0.05 ==> Accept Ho

# Residual plots
newer.par = par(mfrow = c(2,2))
plot(reg1e)
newer.par
```

The SW test has a p-value < 0.05 and hence we conclude that errors are normally distributed

The BP test provides a p-value of 0.3104 and hence we reject Ho and conclude that heteroskedasticity is present.

From the residuals vs fitted values plot we see that the errors are now randomly distributed. Outliers are also reduced.

The QQ plot line is at 45 degrees and points to normal distribution.

We now see that all test results are aligned. The R2 & adj R2values are very low and hence, we may need further transformation of X to make this usable for real world scenarios.

## Problem 2

Refer to the CDI data set. A regression model relating serious crime rate (Y, total serious crimes divided by total population) to population density ($X_1$, total population divided by land area) and unemployment rate ($X_3$) is to be constructed. (30 points, 10 points each)

a-) Fit second-order regression model. Plot the residuals against the fitted values. How
well does the second-order model appear to fit the data? What is $R^2$?

```{r}
cdi <- read.csv('CDI Data.csv')
head(cdi)
summary(cdi)
str(cdi)

crime_rate <- cdi$Total.serious.crimes/cdi$Total.population
pop_den <- cdi$Total.population/cdi$Land.area
unemp <- cdi$Percent.unemployment

y <- crime_rate
x1 <- pop_den
x3 <- unemp

# fit the 2nd order model
y <- crime_rate
x1 <- scale(pop_den, scale = FALSE)
x3 <- scale(unemp, scale = FALSE)
x11 <- x1^2
x32 <- x3^2
x13 <- x1*x3

reg2a <- lm(y~x1+I(x1^2)+x3+I(x3^2)+(x1*x3))
summary(reg2a)

newer.par = par(mfrow = c(2,2))
plot(reg2a)
newer.par
```
The R2 of the model is 0.2485 and adjusted R2 of the model is 0.2398. 

From the residual vs fitted values plot we see that the residuals are not independent and we have outliers in the data while the QQ plot appears to be in order.

b-) Test whether or not all quadratic and interaction terms can be dropped from the regression
model; use $\alpha$ = .01. State the alternatives, decision rule, and conclusion.

```{r}
# fit 1st order model - reduced model
reg2b <- lm(y~x1+x3)
summary(reg2b)

# anova of reduced model and full model
anova(reg2b, reg2a)
```

Comparing the R2 values of full and reduced models we see that the values are nearly similar.

Ho : Quadratic and interaction terms can be dropped
Ha : Quadratic and interaction terms are needed.

The anova test of the full and reduced models also shows that the incremental addition of sum of squares is very small. 

The p-value = 0.02278 is greater than the alpha = 0.01 and we accept Ho; conclude that the variables can be dropped.

c-) Instead of the predictor variable population density, total population ($X_1$ and land area
($X_2$) are to be employed as separate predictor variables, in addition to unemployment rate ($X_3$). The regression model should contain linear and quadratic terms for total population, and linear terms only for land area and unemployment rate. (No interaction terms are to be included in this model.) Fit this regression model and obtain $R^2$. Is this coefficient of multiple determination substantially different from the one for the regression model in part (a)?

```{r}
crime_rate <- cdi$Total.serious.crimes/cdi$Total.population
population <- cdi$Total.population
land_area <- cdi$Land.area
unemp <- cdi$Percent.unemployment

y <- crime_rate
x1 <- scale(population, scale = FALSE)
x2 <- scale(land_area, scale = FALSE)
x3 <- scale(unemp, scale = FALSE)

x12 <- x1

reg2c <- lm(y~x1 + I(x1^2)+x2+x3)
summary(reg2c)

# comparing with part a
# we assume that 2c is the reduced model since it has quadratic term for x1 and linear terms for others. 
anova(reg2c, reg2a)

```

The R2 of the model in part 'c' is 0.1444 with adjusted R2 of 0.1365. 

The R2 of the model in part 'a' is 0.2485 with adjusted R2 of 0.2398. 

Ho : Interaction terms are not needed; 2a and 2c are similar
Ha : Interaction terms are needed; 2a and 2c are substantially different

The anova test gives us a p-value of 6.46e-14 which means that the result is significant at alpha = 0.001

Hence, we reject Ho conclude that the result in part 'c' is substantially different from that in part 'a'.

## Problem 3 

Refer to the CDI data set. The number of active physicians (Y) is to be regressed against total population ($X_1$), total personal income ($X_2$), and geographic region ($X_3$, $X_4$ , $X_5$). (20 points, 10 points each)

("("Geographic region classification is that used by the U.S. Bureau of the Census, where: 1 = NE, 2 = NC, S = 3, W=4")

a-)  Fit a first-order regression model. Let $X_3$ = 1 if NE and 0 otherwise, $X_4$ = 1 if NC and 0 otherwise, and $X_5$ = 1 if S and 0 otherwise. Examine whether the effect for the northeastern region on number of active physicians differs from the effect for the north central region by constructing an appropriate 90 percent
confidence interval. Interpret your interval estimate.

```{r}
y <- cdi$Number.of.active.physicians
x1 <- cdi$Total.population
x2 <- cdi$Total.personal.income
x3 <- as.numeric(cdi$Geographic.region==1) # NE
x4 <- as.numeric(cdi$Geographic.region==2) # NC
x5 <- as.numeric(cdi$Geographic.region==3) # S

reg3a <- lm(y~x1+x2+x3+x4+x5)
summary(reg3a)

# confidence interval
confint(reg3a, level = 1-0.1/2)

```

The model has a very high R2 of 0.9011 and adjusted R2 of 0.8999

x3 and x4 represent the NE and NC regions respectively. As we can see from above, both are significant and have similar intercept and p-values. Confidence intervals for both are also similar. 

Hence, we conclude that both have similar effects. 

b-) Test whether any geographic effects are present; use $\alpha$ = .10. State the alternatives, decision
rule, and conclusion. What is the P-value of the test?

```{r}
# reduced model without geographic effects
reg3b <- lm(y~x1+x2)
summary(reg3b)

# anova of full and reduced model.
anova(reg3b, reg3a)
```

Ho : geographic variables not needed
Ha : geographic variables are needed

As seen above the p-vale is 0.121 which is greater than alpha = 0.05. Hence we accept Ho and conclude that geographic variables are not needed.