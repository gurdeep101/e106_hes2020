---
title: "Homework 1 Solutions"
author: "Gurdeep Singh"
date: "9/14/2020"
output:
  html_document: default
  pdf_document: default
---


## Problem 1

	Refer to the Grade point average Data. The director of admissions of a small college selected 120 students at random from the new freshman class in a study to determine whether a student's grade point average (GPA) at the end of the freshman year (Y) can be predicted from the ACT test score (X). (30 points)

a-)Obtain the least squares estimates of $\beta_{0}$ and $\beta_{1}$, and state the estimated regression function. (5pts)\
b-)	Plot the estimated regression function and the data. "Does the estimated regression function appear to fit the data well? (5pts)\
c-)Obtain a point estimate of the mean freshman GPA for students with ACT test score X = 30. (5pts)\
d-)What is the point estimate of the change in the mean response when the entrance test score increases by one point? (5pts)\
e-)Obtain the residuals $\epsilon_{i}$. Do they sum to zero? (5pts)\
f-)Estimate $\sigma$^2 and $\sigma$. In what units is σ expressed? (5pts)\

# Solutions:
a-)
Solution:
```{r}
library(knitr)

# read in data
gpa <- read.csv("/cloud/project/HW1/Grade Point Average Data.csv")
colnames(gpa) = c('student_gpa', 'act_score')
head(gpa)

# fit regression, obtain coefficients and residuals
reg_q1 <- lm(student_gpa~act_score, data = gpa)
print(reg_q1$coefficients)
intercept_q1 = reg_q1$coefficients[1]
act_score_q1 = reg_q1$coefficients[2]
res_q1 = reg_q1$residuals
```
As seen above, the coefficients are $\beta_0$ = 2.11404929 and $\beta_1$ = 0.03882713

b) 
Solution: 
```{r}
library(knitr)

plot(gpa$act_score, gpa$student_gpa, xlab = "ACT Test Score", ylab = "GPA")
abline(reg_q1, col = 'red')
```

As seen above the points are widely distributed and not clustered around the line. Hence the estimated regression function is not a good fit for the data provided.

c) 
Solution: 
```{r}
act_score = 30
mean_freshman_gpa = intercept_q1 + (act_score * act_score_q1)
mean_freshman_gpa
```
Point estimate of the mean freshman GPA for students with score 30 is 3.278863

d) 
Solution: 
```{r}
print(act_score_q1)
```
For a 1 point increase in entrance test score the GPA increases by the $beta_1$ coefficient = 0.0388 points

e) 
Solution: 
```{r}
res_q1[1:10]
ssr_q1 = sum(res_q1)
print(ssr_q1)
```

The residuals are not exactly zero but a very small value as seen above

f) 
Solution: 
```{r}
ei2 = sum((res_q1)^2)
sigma2 = ei2/(length(res_q1)-2)
sigma = sqrt(sigma2)

print(sigma2)
print(sigma)

```
$\sigma$ is expressed in units of GPA

## Problem 2

Typographical errors shown below are the number of galleys for a manuscript (X) and the dollar cost of correcting typographical errors (Y) in a random sample of recent orders handled by a firm specializing in technical manuscripts. Assume that the regression model Yi = β1X1 + ε_i  is appropriate, with normally distributed independent error terms whose variance is a σ^2 = 16. (20 pts)

a) Evaluate the likelihood function for $\beta_{1}= 1,2, 3,…,100$. For which of $\beta_{1}$ values is the likelihood function largest? (10pts)\

b) The maximum likelihood estimator is $b_{1}=\sum X_{i} Y_{i}/\sum X_{i}^2$.  Find the maximum likelihood estimate. Are your results in part (a) consistent with this estimate? (10 pts)\

## Solutions:
a) 
```{r}
# input data
x_num_galley <- c(7, 12, 4, 14, 25, 30)
y_corr_cost <- c(128, 213, 75, 250, 446, 540)
n_beta <- 100
sig2_err <- 16 # variance given
#sig_err <- sqrt(sig2_err)

# empty vectors to store output
lkhood_val <- vector(mode = 'integer', length = n_beta) # to store all likelihood values
#iteration_lkhood <- vector(mode = 'integer', length = length(x_num_galley))

for (beta_val in 1: n_beta) {
  #print(beta_val)
  interim1 <-  beta_val * x_num_galley
  interim2 <-  (y_corr_cost - interim1)^2
  interim3 <-  sum(interim2)
  interim4 <- exp(interim3/(-2*sig2_err))
  interim5 <- interim4/((2*pi*sig2_err)^(length(x_num_galley)/2))
  lkhood_val[beta_val] <- interim5
}
#print(lkhood_val)
which.max(lkhood_val)

# define likelihood function 
#lkhood_func <- function(x, b, sig_sq = sig2_err, sigma_val = sig_err) {
 # interim1 <- -0.5 * ((x-b/sigma_val)^2)
  #interim2 <- 1/(sigma_val*sqrt(2*pi))
#  return (interim2 * exp(interim1))
#}

#x <- 0
#for (i in n_iter) {
 # #print(i)
  #for (xindex in 1:length(num_galley)) {
   # x <- x+1
    #print(x)
    #iteration_lkhood[xindex] <- lkhood_func(num_galley[xindex], i)
  #}
  #lkhood_val[i] <- prod(iteration_lkhood)
#}

```
b) 

```{r}
mle_2b <- sum(x_num_galley*y_corr_cost)/sum(x_num_galley * x_num_galley)
mle_2b
```

As seen above the results in part 2a and part 2b are consistent.

## Problem 3

Refer to the CDI data set. The number of active physicians in a CDI (Y) is
expected to be related to total population, number of hospital beds, and total personal income. (30 points)

a)	Regress the number of active physicians in turn on each of the three predictor variables. State the estimated regression functions. (10 points)\
b)	Plot the three estimated regression functions and data on separate graphs. Does a linear regression relation appear to provide a good fit for each of the three predictor variables? (10 points)\
c)	Calculate MSE for each of the three predictor variables. Which predictor variable leads to the smallest variability around the fitted regression line? Which variable would you use the estimate Y and why? (10 points)\


## Solutions

a) 

```{r}
# read in data
cdi <- read.csv("/cloud/project/HW1/CDI Data.csv")
head(cdi)
colnames(cdi)

# fit regression separately for each variable 
reg_q2_tot_pop <- lm(Number.of.active.physicians~Total.population, data = cdi)
reg_q2_tot_pop$coefficients

reg_q2_num_beds <- lm(Number.of.active.physicians~Number.of.hospital.beds, data = cdi)
reg_q2_num_beds$coefficients

reg_q2_tot_income <- lm(Number.of.active.physicians~Total.personal.income, data = cdi)
reg_q2_tot_income$coefficients
colnames(cdi)
```
b) 
```{r}
plot(cdi$Total.population, cdi$Number.of.active.physicians, xlab = 'Total Population', ylab = 'Number of Active Physicians')
abline(reg_q2_tot_pop, col = 'red')

plot(cdi$Number.of.hospital.beds, cdi$Number.of.active.physicians, xlab = 'Number of Hospital beds', ylab = 'Number of Active Physicians')
abline(reg_q2_num_beds, col = 'red')

plot(cdi$Total.personal.income, cdi$Number.of.active.physicians, xlab = 'Total Personal Income', ylab = 'Number of Active Physicians')
abline(reg_q2_tot_income, col = 'red')

```
c) 
```{r}
sse_q2_num_beds = sum((reg_q2_num_beds$residuals)^2)
mse_q2_num_beds = sse_q2_num_beds/(length(reg_q2_num_beds$residuals)-2)
mse_q2_num_beds

sse_q2_tot_income = sum((reg_q2_tot_income$residuals)^2)
mse_q2_tot_income = sse_q2_tot_income/(length(reg_q2_tot_income$residuals)-2)
mse_q2_tot_income

sse_q2_tot_pop = sum((reg_q2_tot_pop$residuals)^2)
mse_q2_tot_pop = sse_q2_tot_pop/(length(reg_q2_tot_pop$residuals)-2)
mse_q2_tot_pop
```
## Problem 4
Refer to the CDI data set. Use the number of active physicians as Y and total personal income as X. Select 1,000 random samples of 400 observations, fit the regression model and record $\beta_{0}$ and $\beta_{1}$ for each selected sample. Calculate the mean and variance of $\beta_{0}$ and $\beta_{1}$ based on the 1,000 different regression line and compare against the regression model in question 3 part a. (20 points)

## Solution: 

```{r}
colnames(cdi)
```
